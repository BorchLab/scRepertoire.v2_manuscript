```{r}
setwd("supplemental-analysis/combineTCR-benchmark/R-benchmark")
source(".Rprofile")

suppressPackageStartupMessages({

library(magrittr)
library(bench)
library(data.table)
library(purrr)
library(logger)

})
```

MAJOR NOTE: scRepertoire v1's loadContigs used the filename `filtered_contig_annotation.csv` that omitted the `s` before `.csv`

```{r}
suppressPackageStartupMessages({

library(scRepertoire1)
library(scRepertoire)
library(immunarch)
library(Platypus)

})

# create list of of TCR data loader functions to be benchmarked
processors <- list(
    # scRepertoire1_mb = function(dataset_folder) {
    #     scRepertoire1::combineTCR(scRepertoire1::loadContigs(dataset_folder))
    # },
    # scRepertoire2_mb = function(dataset_folder) {
    #     scRepertoire::combineTCR(scRepertoire::loadContigs(dataset_folder))
    # },
    immunarch_mb = function(dataset_folder) {
        immunarch::repLoad(paste0(dataset_folder, "/filtered_contig_annotation.csv"))
    }#,
    # platypus = function(dataset_folder) {
    #     Platypus::VDJ_GEX_matrix(
    #         VDJ.out.directory.list = list(dataset_folder),
    #         GEX.integrate = FALSE,
    #         VDJ.combine = TRUE,
    #         parallel.processing = "none",
    #         trim.and.align = FALSE,
    #         integrate.GEX.to.VDJ = FALSE,
    #         integrate.VDJ.to.GEX = FALSE,
    #         exclude.GEX.not.in.VDJ = FALSE,
    #         filter.overlapping.barcodes.GEX = FALSE,
    #         filter.overlapping.barcodes.VDJ = FALSE,
    #         get.VDJ.stats = FALSE
    #     )
    # }#,
    # Immcantation = function(dataset_folder) {
    # # TODO
    # }
)
```

```{r}
DATASET_DIR <- "../datasets/"

#' assuming b is a bench::mark result for a single expression,
#' return a 1 row data.frame of the results
get_bench_record <- function(b) {

    data.frame(

        # runtime stats
        min = as.character(b$min),
        median = as.character(b$median),
        mean = as.character(mean(b$time[[1]])),
        max = as.character(max(b$time[[1]])),
        sd = as.character(as_bench_time(sd(b$time[[1]]))),
        ci95 = as.character(as_bench_time(calc_mean_conf_interval(b$time[[1]])),

        # memory stats
        mem_alloc = as.character(b$mem_alloc),
        peak_mem_alloc = as.character(bench::as_bench_bytes(get_peak_mem_alloc(b)))),

        # gc stats
        num_gc = b$n_gc,
        gc0_mean = mean(b$gc[[1]]$level0),
        gc0_median = median(b$gc[[1]]$level0),
        gc0_min = min(b$gc[[1]]$level0),
        gc0_max = max(b$gc[[1]]$level0),
        gc1_mean = mean(b$gc[[1]]$level1),
        gc1_median = median(b$gc[[1]]$level1),
        gc1_min = min(b$gc[[1]]$level1),
        gc1_max = max(b$gc[[1]]$level1),
        gc2_mean = mean(b$gc[[1]]$level2),
        gc2_median = median(b$gc[[1]]$level2),
        gc2_min = min(b$gc[[1]]$level2),
        gc2_max = max(b$gc[[1]]$level2)
    )
}

as_bench_time <- function(x, unit = "s") {
    if (!is.numeric(x)) return(bench::as_bench_time(x))
    unit_converter = c(
        "w" = 604800, "d" = 86400, "h" = 3600, "m" = 60, "s" = 1, "ms" = 1e-3, "Âµs" = 1e-6, "ns" = 1e-9
    )
    bench::as_bench_time(x * unname(unit_converter[unit]))
}

get_peak_mem_alloc <- function(bench_result_single_expr) {
    memory_bytes <- bench_result_single_expr$memory[[1]] %>%
        dplyr::filter(what == "alloc") %>%
        dplyr::pull(bytes)
    memory_bytes <- memory_bytes[!is.na(memory_bytes)]
    if (length(memory_bytes) == 0) return(0)
    max(memory_bytes)
}

calc_mean_conf_interval <- function(x, s = sd(x), lvl = 0.95) {
    # 2 tailed T distribution quantiles are used instead of z, so lvl need to be transformed to 2 tailed
    qt(p = 0.5 + (lvl / 2), df = length(x) - 1) * s / sqrt(length(x))
}
```

```{r}
ITERATIONS <- 10L
dataset_paths <- list.dirs(DATASET_DIR, full.names = TRUE, recursive = FALSE) %>%
    .[order(as.numeric(gsub(".*/", "", .)))] %>% .[6:length(.)]

for (i in seq_along(processors)) {
    
    logger::log_info("Starting Benchmarking of {names(processors)[i]}")
    processor <- processors[[i]]
    output_filename <- paste0("../results/", names(processors)[i], ".csv")
    benchmark_results <- data.frame()

    for (dataset_path in dataset_paths) {
        #gc(verbose = FALSE)
        dataset_size <- as.integer(strsplit(dataset_path, "/")[[1]][3])
        logger::log_info("Benchmarking dataset size {dataset_size}")

        # TODO: possibly need a tryCatch for out of memory errors
        benchmark_record <-
            bench::mark(processor(dataset_path), iterations = ITERATIONS, filter_gc = FALSE, check = FALSE) %>%
            get_bench_record() %>%
            dplyr::mutate(dataset_size = dataset_size, .before = 1)

        benchmark_results %<>% rbind(benchmark_record)
        data.table::fwrite(benchmark_results, output_filename)
        logger::log_success("Completed Benchmarking dataset size {dataset_size}")
    }
    
    logger::log_success("Completed Benchmarking of {names(processors)[i]}")
}
```

```{r}
sessionInfo()
```

```{r}
i <- 1
    
logger::log_info("Starting Benchmarking of {names(processors)[i]}")
processor <- processors[[i]]
output_filename <- paste0("../results/", names(processors)[i], ".csv")
benchmark_results <- data.frame()
dataset_path <- dataset_paths[6]

#gc(verbose = FALSE)
dataset_size <- as.integer(strsplit(dataset_path, "/")[[1]][3])
logger::log_info("Benchmarking dataset size {dataset_size}")

# TODO: possibly need a tryCatch for out of memory errors
benchmark_result <- bench::bench_memory(processor(dataset_path))
print(as_bench_bytes(get_peak_memory_bytes(benchmark_result)))
# benchmark_record <-
#     data.frame(mem_alloc = benchmark_result$mem_alloc, peak_mem_alloc = as.character(max(benchmark_result$memory[[1]]$bytes))) %>%
#     dplyr::mutate(dataset_size = dataset_size) %>%
#     dplyr::relocate(dataset_size)

# benchmark_results %<>% rbind(benchmark_record)
# data.table::fwrite(benchmark_results, output_filename)
# logger::log_success("Completed Benchmarking dataset size {dataset_size}")
```