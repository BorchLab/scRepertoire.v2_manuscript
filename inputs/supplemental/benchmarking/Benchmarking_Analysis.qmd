---
title: "Benchmarking Quantification"
format: html
editor: visual
---

# Setting up

```{r setup, include=FALSE}
library(magrittr)
library(bench)
library(data.table)
library(purrr)
library(logger)

# Create results directory if it doesn't exist
dir.create("results", showWarnings = FALSE)
```

## Making Benchmarking Data Sets

```{r eval=FALSE}
# Loading 10x Contig Data scrapped from GEO
master.TCR <- readRDS("~/Documents/VaildationContigs.rds")

dataset_sizes <- as.integer(2000* 2^(0:9))

# Output folders for validation/replicates
for (size in dataset_sizes) {
  # Create main dataset folder
  dir.create(file.path("datasets", size), recursive = TRUE, showWarnings = FALSE)
  
  # Create replicate subfolders
  for (i in 1:10) {
    dir.create(file.path("datasets", size, paste0("replicate", i)), showWarnings = FALSE)
  }
}

# Output validation replicates
# Loop is really slow to ensure non-duplicate barcodes from other samples - this breaks vdjdj

# Dictionary of sample/barcode pairs
x <- master.TCR %>%
  distinct(barcode, sample)

set.seed(123)
for (size in dataset_sizes) {
 # randomly assign each barcode to only one of its samples
      lookup <- x %>%
        group_by(barcode) %>%
        slice_sample(n = 1) %>%
        ungroup()
      
  for (i in seq_len(10)) {

    # 2) sample exactly `size` barcodes out of that
    sampled_pairs <- lookup %>%
      slice_sample(n = size) %>% 
      group_by(barcode) %>%
        slice_sample(n = 1) %>%
        ungroup()

    # 3) pull all rows from master.TCR for those (barcode, sample) pairs
    replicate_df <- master.TCR %>%
      semi_join(sampled_pairs, by = c("barcode", "sample")) %>% 
      filter(chain %in% c("TRA", "TRB")) %>%
      group_by(barcode, chain) %>%
      slice_max(order_by = reads, n=1) %>%
      unique() %>% 
      ungroup %>%
      group_by(barcode) %>%
      mutate(raw_clonotype_id = cur_group_id()) %>%
      ungroup()

    # write it out
    out_dir <- file.path("datasets", size, paste0("replicate", i))
    dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
    write.csv(
      replicate_df,
      file.path(out_dir, "filtered_contig_annotation.csv"),
      row.names = FALSE,
      quote = FALSE
    )
    write.csv(
      replicate_df,
      file.path(out_dir, "filtered_contig_annotations.csv"),
      row.names = FALSE,
      quote = FALSE
    )
  }
}
```

## Define Pipelines

```{r pipelines}
processors <- list(
  immunarch = function(ds_path) {
    immunarch::repLoad(
      file.path(ds_path, "filtered_contig_annotation.csv"),
      .mode = "paired", 
      .coding = FALSE
    )
  },
  scRepertoire2 = function(ds_path) {
    df <- scRepertoire::loadContigs(input = ds_path)
    scRepertoire::combineTCR(df)
  },
  scRepertoire1 = function(ds_path) {
    df <- scRepertoire1::loadContigs(dir = ds_path)
    scRepertoire1::combineTCR(df)
  },
  djvdj = function(ds_path) {
    df <-  djvdj::import_vdj(vdj_dir = ds_path)
  }
)
```

## Benchmark Loop

```{r benchmark, results='hide'}
dataset_sizes <- as.integer(2000* 2^(0:9))

## Load previous results if they exist
benchmark_file <- "results/benchmark_results_all_iterations.csv"

if (file.exists(benchmark_file)) {
  benchmark_results <- fread(benchmark_file)
} else {
  benchmark_results <- data.table(
    pipeline      = character(),
    dataset_size  = integer(),
    iteration     = integer(),
    time_s        = numeric(),
    mem_MB        = numeric()
  )
}

# Track warm-ups to avoid repeating them
warmup_done <- data.table(
  pipeline = character(),
  dataset_size = integer()
)

for (size in dataset_sizes) {
  for (rep in 1:10) {
    ds_dir <- file.path("datasets", size, paste0("replicate", rep))
    for (pipe in names(processors)) {
      
      # Geometric scaling --> scRepertoire cannot combine 
      #512000 on local machine
      if (pipe == "scRepertoire1" & size > 256000) {
        logger::log_info("Skipping {pipe} on {size} clones (replicate {rep}) - exceeds memory limit.")
        next
      }
      
      # Check if this combo exists
      already_done <- benchmark_results[
        pipeline == pipe & dataset_size == size & iteration == rep
      ]
      
      if (nrow(already_done) > 0) {
        logger::log_info("Skipping {pipe} on {size} clones (replicate {rep}) - already done.")
        next
      }

      # WARM-UP: once per pipeline + dataset size 
      if (nrow(warmup_done[pipeline == pipe & dataset_size == size]) == 0) {
        logger::log_info("Warming up {pipe} on {size} clones...")
        invisible(processors[[pipe]](ds_dir))
        gc()  # optional: clear memory after warm-up
        warmup_done <- rbind(warmup_done, data.table(pipeline = pipe, dataset_size = size))
      }

      # Actual benchmark
      logger::log_info("Benchmarking {pipe} on {size} clones (replicate {rep})...")
      bm <- bench::mark(
        processors[[pipe]](ds_dir),
        iterations = 1,
        memory     = TRUE
      )
      time_s <- as.numeric(bm$time[[1]])
      mem_MB <- as.numeric(bm$mem_alloc[[1]]) / 1024^2

      benchmark_results <- rbind(
        benchmark_results,
        list(
          pipeline      = pipe,
          dataset_size  = size,
          iteration     = rep,
          time_s        = time_s,
          mem_MB        = mem_MB
        ),
        use.names = TRUE
      )

      # Save after every benchmark 
      fwrite(
        benchmark_results,
        benchmark_file
      )
    }
  }
}


```
