---
title: "Benchmarking Quantification"
format: html
editor: visual
---

# Setting up

```{r setup, include=FALSE}
library(magrittr)
library(bench)
library(data.table)
library(purrr)
library(logger)

# Setting up python
library(reticulate)
scirpy <- import("scirpy", delay_load = TRUE)
psutil <- import("psutil", delay_load = TRUE)
time <- import("time", delay_load = TRUE)


# Create results directory if it doesn't exist
dir.create("results", showWarnings = FALSE)
```

## Making Benchmarking Datasets

```{r eval=FALSE}
# Loading 10x Contig Data scrapped from GEO
master.TCR <- readRDS("~/Documents/VaildationContigs.rds")

# Generating sample-specific barcodes
x <- master.TCR %>%
        group_by(sample, barcode) %>%
        summarise(n = n())

dataset_sizes <- as.integer(2000* 2^(0:9))

# Output folders for validation/replicates
for (size in dataset_sizes) {
  # Create main dataset folder
  dir.create(file.path("datasets", size), recursive = TRUE, showWarnings = FALSE)
  
  # Create replicate subfolders
  for (i in 1:10) {
    dir.create(file.path("datasets", size, paste0("replicate", i)), showWarnings = FALSE)
  }
}

# Generating invidual replicates
set.seed(123)
for (size in dataset_sizes) {
  for (i in 1:10) {
    # Sample from `x`
    sample.idx <- sample(nrow(x), size)
    sampled_x <- x[sample.idx, ]

    # Create a key to match on both `sample` and `barcode`
    sampled_keys <- paste(sampled_x$sample, sampled_x$barcode, sep = "_")
    master_keys  <- paste(master.TCR$sample, master.TCR$barcode, sep = "_")

    # Filter master.TCR using the composite key
    replicate <- master.TCR[master_keys %in% sampled_keys, ]

    # Write to file
    out_dir <- file.path("datasets", size, paste0("replicate", i))
    dir.create(out_dir, recursive = TRUE, showWarnings = FALSE)
    write.csv(replicate, file.path(out_dir, "filtered_contig_annotations.csv"), row.names = FALSE, quote = FALSE)
    write.csv(replicate, file.path(out_dir, "filtered_contig_annotation.csv"), row.names = FALSE, quote = FALSE)
  }
}
```

## Define Pipelines

```{r pipelines}
processors <- list(
  immunarch = function(ds_path) {
    immunarch::repLoad(
      file.path(ds_path, "filtered_contig_annotation.csv"),
      .mode = "paired", 
      .coding = FALSE
    )
  },
  scRepertoire2 = function(ds_path) {
    df <- scRepertoire::loadContigs(input = ds_path)
    scRepertoire::combineTCR(df)
  },
  scRepertoire1 = function(ds_path) {
    df <- scRepertoire1::loadContigs(dir = ds_path)
    scRepertoire1::combineTCR(df)
  #},
  #scirpy = function(ds_path) {
  #  mem_before <- psutil$Process()$memory_info()$rss
  #  start <- time$time()
  #  scirpy$io$read_10x_vdj(file.path(ds_path, "filtered_contig_annotation.csv"))
  #  end <- time$time()
  #  mem_after <- psutil$Process()$memory_info()$rss
  #  list(
  #    elapsed = end - start,
  #    mem_mb = (mem_after - mem_before) / 1024^2
  #  )
  }
)
```

## Benchmark Loop

```{r benchmark, results='hide'}

dataset_sizes <- as.integer(2000 * 2^(0:9))[1:3] #Only doing small data so far

# Prepare results table
benchmark_results <- data.table(
  pipeline      = character(),
  dataset_size  = integer(),
  iteration     = integer(),
  time_s        = numeric(),
  mem_MB        = numeric()
)

for (size in dataset_sizes) {
  for (rep in 1:10) {
    ds_dir <- file.path("datasets", size, paste0("replicate", rep))
    for (pipe in names(processors)) {
      logger::log_info("Benchmarking {pipe} on {size} clones (replicate {rep})...")
      if (pipe == "scirpy") {
        result <- processors[[pipe]](ds_dir)
        time_s <- result$elapsed
        mem_MB <- result$mem_mb
      } else {
        bm <- bench::mark(
          processors[[pipe]](ds_dir),
          iterations = 1,
          memory     = TRUE
        )
        time_s <- as.numeric(bm$time[[1]])
        mem_MB <- as.numeric(bm$mem_alloc[[1]]) / 1024^2
      }

      benchmark_results <- rbind(
        benchmark_results,
        list(
          pipeline      = pipe,
          dataset_size  = size,
          iteration     = rep,
          time_s        = time_s,
          mem_MB        = mem_MB
        ),
        use.names = TRUE
      )
    }
  }
  fwrite(
    benchmark_results,
    "results/benchmark_results_all_iterations.csv"
  )
}
```
